<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>CREST-Deep Weekly Meeting</title>
  <meta name="description" content="2017-03-27">

  <!-- CSS files -->
  <link rel="stylesheet" href="/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/main.css">

  <link rel="canonical" href="/articles/2017-03/crest-meeting">
  <link rel="alternate" type="application/rss+xml" title="Complex Network Research Group (Murata Lab)" href="/feed.xml" />

  <!-- Icons -->
  <!-- 16x16 -->
  <link rel="shortcut icon" href="/favicon.ico">
  <!-- 32x32 -->
  <link rel="shortcut icon" href="/favicon.png">
</head>


<body>
  <div class="row">
    <div class="col s12 m3">
      <div class="table cover">
        

<div class="cover-card table-cell table-middle">
  
  <img src="/img/net-logo.png" alt="" class="avatar">
  
  <a href="/" class="author_name">Murata Laboratory</a>
  <span class="author_job">Complex Network @ Titech</span>
  <span class="author_bio mbm">Our laboratory studies behaviors and structures of complex networks. The official website can be accessed at [net.c.titech.ac.jp]. Check the archive session for a list of all posts.</span>
  <nav class="nav">
    <ul class="nav-list">
      <li class="nav-item">
        <a href="/">home</a>
      </li>
       
      <li class="nav-item">
        <a href="/archive/">Archive</a>
      </li>
          
      <li class="nav-item">
        <a href="/topics/">Topics</a>
      </li>
            
      <li class="nav-item">
        <a href="/tags/">Tags</a>
      </li>
       
    </ul>
  </nav>
  <script type="text/javascript">
  // based on http://stackoverflow.com/a/10300743/280842
  function gen_mail_to_link(hs, subject) {
    var lhs,rhs;
    var p = hs.split('@');
    lhs = p[0];
    rhs = p[1];
    document.write("<a class=\"social-link-item\" target=\"_blank\" href=\"mailto");
    document.write(":" + lhs + "@");
    document.write(rhs + "?subject=" + subject + "\"><i class=\"fa fa-fw fa-envelope\"></i><\/a>");
  }
</script>
<div class="social-links">
  <ul>
    
    
    
    
    
    
    
    
    
    <li><a href="http://github.com/net-titech" class="social-link-item" target="_blank"><i class="fa fa-fw fa-github"></i></a></li>
    
    
    
    
    
    
    
    <li><a href="https://youtube.com/user/net-titech" class="social-link-item" target="_blank"><i class="fa fa-fw fa-youtube"></i></a></li>
    
    
    
    
    
  </ul>
</div>

</div>

      </div>
    </div>
    <div class="col s12 m9">
      <div class="post-listing">
        <a class="btn" href= "/" >
  Home
</a>



<div id="post">
  <header class="post-header">
    <h1 title="CREST-Deep Weekly Meeting">CREST-Deep Weekly Meeting</h1>
    <span class="post-meta">
      <span class="post-date">
        27 MAR 2017
      </span>
      â€¢
      <span class="read-time" title="Estimated read time">
  
  
    2 mins read
  
</span>

    </span>

  </header>

  <article class="post-content">
    <h1 id="crest-deep-weekly-meeting">2017-03-27 / CREST-Deep Weekly Meeting</h1>

<h2 id="i-classfa-fa-file-texti-literature-update"><i class="fa fa-file-text"></i> Literature Update</h2>

<p>In this week, we have studied several papers regarding techniques and new architectures
for compact deep neural network (especially deep convolutional neural networks).
The list of papers are provided <a href="https://net-titech.github.io/articles/2017-02/deep-compression">here</a>.
We have several observations as follow:</p>

<ul>
  <li>In the area of deep neural network <em>compression</em>, the standard procedure is: <em>pruning</em>, <em>quantization</em>, then <em>Huffman coding</em>. Although the aforementioned procedure yields good compression rate for <strong>storing</strong> a deep convolutional neural network (1/40 to 1/60), we still need to <strong>decompress</strong> a compressed model to its original size in order to run it. None of the proposed models actually run on compressed network. We believe there must be a way to run a compressed network without decompressing it.</li>
  <li>There are some interesting neural network models applying binary weights, block dropout, and discrete cosine transformation to improve theirs speed (training/running) and compressing the model storage space.</li>
  <li>Regarding the benchmark criteria for a deep neural network compression model, not many research actually measure the memory requirement of a DNN model in deployment. We think the exact energy consumption and memory usage of <em>each layer</em> is a very important information to measure the performance of a DNN model.</li>
  <li>The approach from (Ullrich, 2017) read by Choong is similar to the Stochastic Block Model approach. We can generalize such approach.</li>
  <li>Investigate the Determinantal Point Processes on graphs gives some interesting suggestions for graph sampling and neural network summarization.</li>
  <li>SquezeNet is one of the most effective compact deep neural network. It performs particularly well in domain-specific applications. A similar (smaller or higher accuracy) architecture to SquezeNet can be developed.</li>
  <li>Viewing a neural network as a acyclic (multi-partite) network, we can think of each output element (in an output vector) is the result of computation along many <em>paths</em>. This view yields some insight about a deep neural network (Kawaguchi, 2016), and also inspired for some other representation of a deep neural network using only one distribution and one matrix.</li>
</ul>

<h2 id="i-classfa-fa-flaski-research-update"><i class="fa fa-flask"></i> Research Update</h2>

<p>We have run several DNN compression benchmark provided by (Han, 2016) and (Ullrich, 2017) to recreate their results. As mentioned in the previous session, these models compress the network in term of storage space, not running memory space. On the other hand, we have set up Caffe environment on the new machine (titan-x) and downloaded the full size ImageNet.</p>

<h2 id="i-classfa-fa-bullseyei-next-week-objectives"><i class="fa fa-bullseye"></i> Next Week Objectives</h2>

<p>We have one presentation on April 4th in the meeting with other labs. The content of this presentation is as follow:</p>

<ul>
  <li>Present the current situation of deep model compression. (state of the art algorithms and their limitations)</li>
  <li>Present our complex network approaches (Filter compression, DPP, SBM, Submodularity, Network summarization).</li>
  <li>Discuss about the domain-specific constrain.</li>
</ul>

<p>On the other hand, we will keep exploring and comparing other algorithms and start the benchmark implementation.</p>

  </article>
</div>

<div class="share-buttons">
  <h6>Share on: </h6>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=/articles/2017-03/crest-meeting" class="twitter btn" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=/articles/2017-03/crest-meeting" class="facebook btn" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=/articles/2017-03/crest-meeting" class="google-plus btn" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
    <li>
      <a href="https://news.ycombinator.com/submitlink?u=/articles/2017-03/crest-meeting" class="hacker-news btn" title="Share on Hacker News"><i class="fa fa-hacker-news"></i><span> Hacker News</span></a>
    </li>
    <li>
      <a href="https://www.reddit.com/submit?url=/articles/2017-03/crest-meeting" class="reddit btn" title="Share on Reddit"><i class="fa fa-reddit"></i><span> Reddit</span></a>
    </li>
  </ul>
</div><!-- end share-buttons -->



        <footer>
  &copy; 2017 Murata Laboratory. Official website: <a href="www.net.c.titech.ac.jp">www.net.c.titech.ac.jp</a>
</footer>

      </div>
    </div>
  </div>
  <script type="text/javascript" src="/js/jquery-2.1.4.min.js"></script>
<script type="text/javascript" src="/js/main.js"></script>


</body>
</html>
